# agent_core/config/analysis_config.py

from dataclasses import dataclass
from typing import Dict, List, Any, Optional
from enum import Enum

class AnalysisMode(Enum):
    """åˆ†ææ¨¡å¼æšä¸¾"""
    QUICK = "quick"          # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    STANDARD = "standard"    # æ ‡å‡†åˆ†ææ¨¡å¼  
    DEEP = "deep"           # æ·±åº¦åˆ†ææ¨¡å¼
    CUSTOM = "custom"       # è‡ªå®šä¹‰æ¨¡å¼

@dataclass
class ClinicalTrialsConfig:
    """ä¸´åºŠè¯•éªŒæ£€ç´¢é…ç½®"""
    page_size: int = 10              # æ¯é¡µç»“æœæ•°
    max_pages: int = 2               # æœ€å¤§é¡µæ•°
    max_trials_analyze: int = 20     # æœ€å¤šåˆ†æå¤šå°‘ä¸ªè¯•éªŒ
    use_detailed_description: bool = True  # æ˜¯å¦ä½¿ç”¨è¯¦ç»†æè¿°
    fields_to_analyze: List[str] = None    # è¦åˆ†æçš„å­—æ®µ
    
    def __post_init__(self):
        if self.fields_to_analyze is None:
            self.fields_to_analyze = ["title", "brief_summary", "condition", "phase", "status"]

@dataclass 
class LiteratureConfig:
    """æ–‡çŒ®æ£€ç´¢é…ç½®"""
    max_abstracts: int = 20          # æœ€å¤šæ£€ç´¢å¤šå°‘ç¯‡æ–‡çŒ®
    max_abstracts_analyze: int = 15  # æœ€å¤šåˆ†æå¤šå°‘ç¯‡
    abstract_max_length: int = 500   # æ¯ç¯‡æ‘˜è¦æœ€å¤§é•¿åº¦(å­—ç¬¦)
    include_full_text: bool = False  # æ˜¯å¦åŒ…å«å…¨æ–‡(æœªæ¥åŠŸèƒ½)

@dataclass
class AnalysisDepthConfig:
    """åˆ†ææ·±åº¦é…ç½®"""
    analysis_sections: List[str] = None  # è¦ç”Ÿæˆçš„åˆ†æç« èŠ‚
    prompt_max_length: int = 4000        # æç¤ºè¯æœ€å¤§é•¿åº¦
    response_max_tokens: int = 1500      # å“åº”æœ€å¤§tokenæ•°
    include_citations: bool = True       # æ˜¯å¦åŒ…å«å¼•ç”¨
    generate_summary: bool = True        # æ˜¯å¦ç”Ÿæˆæ€»ç»“
    
    def __post_init__(self):
        if self.analysis_sections is None:
            self.analysis_sections = ["disease_mechanism", "treatment_strategy", "target_analysis"]

@dataclass
class TokenConfig:
    """Tokenä½¿ç”¨é…ç½®"""
    max_input_tokens: int = 8000         # æœ€å¤§è¾“å…¥tokenæ•°
    max_output_tokens: int = 2000        # æœ€å¤§è¾“å‡ºtokenæ•°
    estimated_tokens_per_trial: int = 150    # æ¯ä¸ªè¯•éªŒé¢„ä¼°tokenæ•°
    estimated_tokens_per_abstract: int = 300 # æ¯ç¯‡æ‘˜è¦é¢„ä¼°tokenæ•°
    safety_buffer: float = 0.8           # å®‰å…¨ç¼“å†²åŒº(80%ä½¿ç”¨ç‡)

@dataclass
class PerformanceConfig:
    """æ€§èƒ½é…ç½®"""
    request_timeout: int = 30            # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
    request_delay: float = 0.3           # è¯·æ±‚é—´éš”(ç§’)
    max_concurrent_requests: int = 3     # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    enable_caching: bool = True          # æ˜¯å¦å¯ç”¨ç¼“å­˜
    cache_ttl: int = 3600               # ç¼“å­˜ç”Ÿå­˜æ—¶é—´(ç§’)

@dataclass
class AnalysisConfig:
    """å®Œæ•´åˆ†æé…ç½®"""
    mode: AnalysisMode = AnalysisMode.STANDARD
    clinical_trials: ClinicalTrialsConfig = None
    literature: LiteratureConfig = None  
    analysis_depth: AnalysisDepthConfig = None
    tokens: TokenConfig = None
    performance: PerformanceConfig = None
    
    def __post_init__(self):
        # å¦‚æœæ²¡æœ‰æä¾›å­é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼
        if self.clinical_trials is None:
            self.clinical_trials = ClinicalTrialsConfig()
        if self.literature is None:
            self.literature = LiteratureConfig()
        if self.analysis_depth is None:
            self.analysis_depth = AnalysisDepthConfig()
        if self.tokens is None:
            self.tokens = TokenConfig()
        if self.performance is None:
            self.performance = PerformanceConfig()

class ConfigManager:
    """é…ç½®ç®¡ç†å™¨"""
    
    @staticmethod
    def get_quick_config() -> AnalysisConfig:
        """å¿«é€Ÿæµ‹è¯•é…ç½® - çœTokenï¼Œå¿«é€Ÿè¿è¡Œ"""
        return AnalysisConfig(
            mode=AnalysisMode.QUICK,
            clinical_trials=ClinicalTrialsConfig(
                page_size=3,
                max_pages=1, 
                max_trials_analyze=3,
                use_detailed_description=False,  # ğŸ‘ˆ ä¸ä½¿ç”¨è¯¦ç»†æè¿°
                fields_to_analyze=["title", "brief_summary", "condition"]  # ğŸ‘ˆ åªç”¨æ ¸å¿ƒå­—æ®µ
            ),
            literature=LiteratureConfig(
                max_abstracts=5,
                max_abstracts_analyze=3,
                abstract_max_length=300
            ),
            analysis_depth=AnalysisDepthConfig(
                analysis_sections=["disease_mechanism"],  # ğŸ‘ˆ åªåˆ†æç–¾ç—…æœºåˆ¶
                prompt_max_length=2000,
                response_max_tokens=800,
                include_citations=False,  # ğŸ‘ˆ ä¸åŒ…å«å¼•ç”¨
                generate_summary=True
            ),
            tokens=TokenConfig(
                max_input_tokens=3000,
                max_output_tokens=1000,
                estimated_tokens_per_trial=100,
                estimated_tokens_per_abstract=200
            )
        )
    
    @staticmethod 
    def get_standard_config() -> AnalysisConfig:
        """æ ‡å‡†é…ç½® - å¹³è¡¡è´¨é‡å’Œæ•ˆç‡"""
        return AnalysisConfig(
            mode=AnalysisMode.STANDARD,
            clinical_trials=ClinicalTrialsConfig(
                page_size=10,
                max_pages=2,
                max_trials_analyze=15,
                use_detailed_description=True,
                fields_to_analyze=["title", "brief_summary", "detailed_description", "condition", "phase", "status"]
            ),
            literature=LiteratureConfig(
                max_abstracts=20,
                max_abstracts_analyze=10,
                abstract_max_length=500
            ),
            analysis_depth=AnalysisDepthConfig(
                analysis_sections=["disease_mechanism", "treatment_strategy"],
                prompt_max_length=4000,
                response_max_tokens=1500,
                include_citations=True,
                generate_summary=True
            ),
            tokens=TokenConfig(
                max_input_tokens=8000,
                max_output_tokens=2000
            )
        )
    
    @staticmethod
    def get_deep_config() -> AnalysisConfig:
        """æ·±åº¦åˆ†æé…ç½® - æœ€å…¨é¢çš„åˆ†æ"""
        return AnalysisConfig(
            mode=AnalysisMode.DEEP,
            clinical_trials=ClinicalTrialsConfig(
                page_size=20,
                max_pages=3,
                max_trials_analyze=50,
                use_detailed_description=True,
                fields_to_analyze=["title", "brief_summary", "detailed_description", "condition", "phase", "status", "interventions", "outcomes"]
            ),
            literature=LiteratureConfig(
                max_abstracts=50,
                max_abstracts_analyze=30,
                abstract_max_length=800
            ),
            analysis_depth=AnalysisDepthConfig(
                analysis_sections=["disease_mechanism", "treatment_strategy", "target_analysis"],
                prompt_max_length=8000,
                response_max_tokens=3000,
                include_citations=True,
                generate_summary=True
            ),
            tokens=TokenConfig(
                max_input_tokens=15000,
                max_output_tokens=4000
            )
        )
    
    @staticmethod
    def get_config_by_mode(mode: AnalysisMode) -> AnalysisConfig:
        """æ ¹æ®æ¨¡å¼è·å–é…ç½®"""
        if mode == AnalysisMode.QUICK:
            return ConfigManager.get_quick_config()
        elif mode == AnalysisMode.STANDARD:
            return ConfigManager.get_standard_config()
        elif mode == AnalysisMode.DEEP:
            return ConfigManager.get_deep_config()
        else:
            return ConfigManager.get_standard_config()
    
    @staticmethod
    def estimate_token_usage(config: AnalysisConfig) -> Dict[str, int]:
        """ä¼°ç®—Tokenä½¿ç”¨é‡"""
        ct_config = config.clinical_trials
        lit_config = config.literature
        token_config = config.tokens
        
        # ä¼°ç®—è¾“å…¥token
        trials_tokens = ct_config.max_trials_analyze * token_config.estimated_tokens_per_trial
        abstracts_tokens = lit_config.max_abstracts_analyze * token_config.estimated_tokens_per_abstract
        prompt_tokens = 500  # åŸºç¡€æç¤ºè¯
        
        input_tokens = trials_tokens + abstracts_tokens + prompt_tokens
        
        # ä¼°ç®—è¾“å‡ºtoken
        output_tokens = config.analysis_depth.response_max_tokens * len(config.analysis_depth.analysis_sections)
        
        total_tokens = input_tokens + output_tokens
        
        return {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens, 
            "total_tokens": total_tokens,
            "trials_tokens": trials_tokens,
            "abstracts_tokens": abstracts_tokens,
            "estimated_cost_usd": total_tokens * 0.000002  # ç²—ç•¥ä¼°ç®—æˆæœ¬
        }
    
    @staticmethod
    def validate_config(config: AnalysisConfig) -> List[str]:
        """éªŒè¯é…ç½®åˆç†æ€§"""
        warnings = []
        
        # æ£€æŸ¥Tokené™åˆ¶
        token_estimate = ConfigManager.estimate_token_usage(config)
        if token_estimate["total_tokens"] > config.tokens.max_input_tokens + config.tokens.max_output_tokens:
            warnings.append(f"ä¼°ç®—Tokenä½¿ç”¨é‡({token_estimate['total_tokens']})è¶…è¿‡é™åˆ¶")
        
        # æ£€æŸ¥æ•°æ®é‡
        if config.clinical_trials.max_trials_analyze > 100:
            warnings.append("è¯•éªŒåˆ†ææ•°é‡è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´è¶…æ—¶")
            
        if config.literature.max_abstracts_analyze > 50:
            warnings.append("æ–‡çŒ®åˆ†ææ•°é‡è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´è¶…æ—¶")
        
        # æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§
        if config.clinical_trials.max_trials_analyze > config.clinical_trials.page_size * config.clinical_trials.max_pages:
            warnings.append("è¦åˆ†æçš„è¯•éªŒæ•°é‡è¶…è¿‡æ£€ç´¢æ•°é‡")
            
        return warnings

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•
def example_usage():
    """é…ç½®ä½¿ç”¨ç¤ºä¾‹"""
    
    print("=== é…ç½®ç¤ºä¾‹ ===")
    
    # 1. å¿«é€Ÿæ¨¡å¼
    quick_config = ConfigManager.get_quick_config()
    quick_estimate = ConfigManager.estimate_token_usage(quick_config)
    print(f"å¿«é€Ÿæ¨¡å¼é¢„ä¼°Token: {quick_estimate['total_tokens']}")
    print(f"é¢„ä¼°æˆæœ¬: ${quick_estimate['estimated_cost_usd']:.4f}")
    
    # 2. æ ‡å‡†æ¨¡å¼
    standard_config = ConfigManager.get_standard_config()
    standard_estimate = ConfigManager.estimate_token_usage(standard_config)
    print(f"æ ‡å‡†æ¨¡å¼é¢„ä¼°Token: {standard_estimate['total_tokens']}")
    
    # 3. æ·±åº¦æ¨¡å¼
    deep_config = ConfigManager.get_deep_config()
    deep_estimate = ConfigManager.estimate_token_usage(deep_config)
    print(f"æ·±åº¦æ¨¡å¼é¢„ä¼°Token: {deep_estimate['total_tokens']}")
    
    # 4. éªŒè¯é…ç½®
    warnings = ConfigManager.validate_config(deep_config)
    if warnings:
        print(f"æ·±åº¦æ¨¡å¼è­¦å‘Š: {warnings}")
    
    # 5. è‡ªå®šä¹‰é…ç½®
    custom_config = AnalysisConfig(
        mode=AnalysisMode.CUSTOM,
        clinical_trials=ClinicalTrialsConfig(
            page_size=5,
            max_pages=1,
            use_detailed_description=False
        )
    )
    custom_estimate = ConfigManager.estimate_token_usage(custom_config)
    print(f"è‡ªå®šä¹‰é…ç½®é¢„ä¼°Token: {custom_estimate['total_tokens']}")

if __name__ == "__main__":
    example_usage()